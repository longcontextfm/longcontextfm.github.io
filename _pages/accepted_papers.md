---
layout: page
permalink: /accepted/
title: Accepted Papers
description:
nav: true
nav_order: 3
---

# Accepted Papers

<!-- Please check our [OpenReview page](https://openreview.net/group?id=ICML.cc/2024/Workshop/LCFM&referrer=%5BHomepage%5D(%2F)#tab-accept) for all the accepted papers! -->

<!--
<br>
__Links: [[OpenReview Portal]](https://openreview.net/group?id=NeurIPS.cc/2023/Workshop/Instruction) [[NeurIPS Site]](https://neurips.cc/virtual/2023/workshop/66498)__
<br>__Note:__ Authors are encouraged to contact us to add links to posters, videos, and other materials related to their paper.

---

[Improved Baselines with Visual Instruction Tuning](https://openreview.net/forum?id=yx3Hkx5ved)
<br>Haotian Liu, Chunyuan Li, Yuheng Li, Yong Jae Lee

[Can LLM-Generated Misinformation Be Detected?](https://openreview.net/forum?id=yi8KGilFFk)
<br>Canyu Chen, Kai Shu

[Prometheus: Inducing Evaluation Capability in Language Models](https://openreview.net/forum?id=yeQvl1q8Vy)
<br>Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, Minjoon Seo

[Instruction-tuned LLMs with World Knowledge are More Aligned to the Human Brain](https://openreview.net/forum?id=ydY0xXNhwi)
<br>Khai Loong Aw, Syrielle Montariol, Badr AlKhamissi, Martin Schrimpf, Antoine Bosselut
<br>[[Poster]](https://bkhmsi.github.io/assets/posters/instruction-tuning-brain-align.pdf) [[Video]](https://recorder-v3.slideslive.com/?share=90518&s=4b382389-ff57-4e72-bf89-d59c531c3d4f) [[Arxiv]](https://arxiv.org/abs/2312.00575)

[Ring Attention with Blockwise Transformers for Near-Infinite Context](https://openreview.net/forum?id=xulyCXgIWH)
<br>Hao Liu, Matei Zaharia, Pieter Abbeel

[Reflection-Tuning: Recycling Data for Better Instruction-Tuning](https://openreview.net/forum?id=xaqoZZqkPU)
<br>Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Tianyi Zhou

[Supervised Fine-Tuning of Large Language Models on Human Demonstrations Through the Lens of Memorization](https://openreview.net/forum?id=x6MlSOzbmC)
<br>Yubin Ge, Devamanyu Hazarika, Yang Liu, Mahdi Namazifar

[Grounding Code Generation with Input-Output Specifications](https://openreview.net/forum?id=wq4OaU8tfE)
<br>Yeming Wen, Pengcheng Yin, Kensen Shi, Henryk Michalewski, Swarat Chaudhuri, Alex Polozov

[#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models](https://openreview.net/forum?id=wcSx5VjTPP)
<br>Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Junyang Lin, Chuanqi Tan, Chang Zhou, Jingren Zhou

[Training Speech Recognition Models to Follow Instructions](https://openreview.net/forum?id=wYLASkYFJU)
<br>Cheng-I Lai, Zhiyun Lu, Liangliang Cao, Ruoming Pang

[Enhanced Visual Instruction Tuning for Text-Rich Image Understanding](https://openreview.net/forum?id=vDXvtytjdX)
<br>Yanzhe Zhang, Ruiyi Zhang, Jiuxiang Gu, Yufan Zhou, Nedim Lipka, Diyi Yang, Tong Sun

[Cross-Modal Learning for Chemistry Property Prediction: Large Language Models Meet Graph Machine Learning](https://openreview.net/forum?id=umtG8Hs32R)
<br>Sagar Sakhinana, Venkataramana Runkana

[Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers](https://openreview.net/forum?id=twgpHJmvJy)
<br>Xiaoqiang Lin, Zhaoxuan Wu, Zhongxiang Dai, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet, Bryan Kian Hsiang Low
<br>[[Video]](https://www.bilibili.com/video/BV14C4y1n7Ji/) [[Project Page]](https://xqlin98.github.io/INSTINCT/)

[Learning to Generate Instructions to Adapt Language Models to New Tasks](https://openreview.net/forum?id=tw2w8rgWMV)
<br>Nihal Nayak, Yiyang Nan, Avi Trost, Stephen Bach

[An Emulator for Fine-tuning Large Language Models using Small Language Models](https://openreview.net/forum?id=tdqZUxKfIj)
<br>Eric Mitchell, Rafael Rafailov, Archit Sharma, Chelsea Finn, Christopher Manning

[Evaluating Large Language Models at Evaluating Instruction Following](https://openreview.net/forum?id=tC2lDRhHNT)
<br>Zhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya Goyal, Danqi Chen

[Instruction-following Evaluation through Verbalizer Manipulation](https://openreview.net/forum?id=rz6u0qOVth)
<br>Shiyang Li, Jun Yan, Hai Wang, Zheng Tang, Xiang Ren, Vijay Srinivasan, Hongxia Jin

[Delve into PPO: Implementation Matters for Stable RLHF](https://openreview.net/forum?id=rxEmiOEIFL)
<br>Rui Zheng, Shihan Dou, Songyang Gao, Yuan Hua, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Yuhao Zhou, Limao Xiong, Lu Chen, Zhiheng Xi, Nuo Xu, Wenbin Lai, Minghao Zhu, Haoran Huang, Tao Gui, Qi Zhang, Xuanjing Huang

[NLPBench: Evaluating Large Language Models on Solving NLP Problems](https://openreview.net/forum?id=qN9T4cmTEw)
<br>Linxin Song, Jieyu Zhang, Lechao Cheng, Pengyuan Zhou, Tianyi Zhou, Irene Li

[Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing](https://openreview.net/forum?id=psJibeRV0T)
<br>Xinyu Hu, Pengfei Tang, Simiao Zuo, Zihan Wang, Bowen Song, Qiang Lou, Jian Jiao, Denis Charles

[URIAL: Tuning-Free Instruction Learning and Alignment for Untuned LLMs](https://openreview.net/forum?id=pFHeZzl5ft)
<br>Bill Yuchen Lin, Abhilasha Ravichander, Ximing Lu, Nouha Dziri, Melanie Sclar, Khyathi Chandu, Chandra Bhagavatula, Yejin Choi

[Verbosity Bias in Preference Labeling by Large Language Models](https://openreview.net/forum?id=magEgFpK1y)
<br>Keita Saito, Akifumi Wachi, Koki Wataoka, Youhei Akimoto

[Automatic Construction of a Korean Toxic Instruction Dataset for Ethical Tuning of Large Language Models](https://openreview.net/forum?id=kqtB2AueFm)
<br>SungJoo Byun, Dongjun Jang, Hyemi Jo, Hyopil Shin

[Fine-tuning Language Models for Factuality](https://openreview.net/forum?id=kEK08VdSO5)
<br>Katherine Tian, Eric Mitchell, Huaxiu Yao, Christopher Manning, Chelsea Finn

[Self-RAG: Self-reflective Retrieval Augmented Generation](https://openreview.net/forum?id=jbNjgmE0OP)
<br>Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, Hannaneh Hajishirzi

[FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation](https://openreview.net/forum?id=fhSTeAAVb6)
<br>Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, Hannaneh Hajishirzi

[Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models](https://openreview.net/forum?id=fT3gT2QKOb)
<br>Sagar Sakhinana, Sannidhi Geethan, Venkataramana Runkana

[Exploring and Improving the Spatial Reasoning Abilities of Large Language Models](https://openreview.net/forum?id=fHtLiX36r6)
<br>Manasi Sharma

[Investigating the Effects of Zero-Shot Chain-of-Thought on Empathetic Dialogue Generation](https://openreview.net/forum?id=eBu11K7THc)
<br>Young-Jun Lee, Dokyong Lee, Jihui Im, Joo Won Sung, Ho-Jin Choi
<br>[[Poster]](/assets/pdf/55poster.pdf)

[Analyzing and Mitigating Object Hallucination in Large Vision-Language Models](https://openreview.net/forum?id=czQZ4aLUb6)
<br>Yiyang Zhou, Chenhang Cui, Jaehong Yoon, Linjun Zhang, Zhun Deng, Chelsea Finn, Mohit Bansal, Huaxiu Yao

[Chain of Natural Language Inference for Reducing Large Language Model Hallucinations](https://openreview.net/forum?id=byNSabn9cA)
<br>Deren Lei, Yaxi Li, Mengya Hu, Mingyu Wang, Xi Yun

[Chain-of-Thought Reasoning is a Policy Improvement Operator](https://openreview.net/forum?id=bH64KCBzqS)
<br>Hugh Zhang, David Parkes

[Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints](https://openreview.net/forum?id=b519y1V7fX)
<br>Chaoqi Wang, Yibo Jiang, Chenghao Yang, Han Liu, Yuxin Chen

[Interactive Planning Using Large Language Models for Partially Observable Robotics Tasks](https://openreview.net/forum?id=apEdj9baZx)
<br>Lingfeng Sun, Devesh Jha, Chiori Hori, Siddarth Jain, Radu Corcodel, Xinghao Zhu, Masayoshi Tomizuka, Diego Romeres

[Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs](https://openreview.net/forum?id=YA56eOURrG)
<br>Qingru Zhang, Chandan Singh, Liyuan Liu, Xiaodong Liu, Bin Yu, Jianfeng Gao, Tuo Zhao

[Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications](https://openreview.net/forum?id=V09d7AMh15)
<br>Fengqing Jiang, Zhangchen Xu, Luyao Niu, Boxin Wang, Jinyuan Jia, Bo Li, Radha Poovendran

[Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game](https://openreview.net/forum?id=UWymGURI75)
<br>Sam Toyer, Olivia Watkins, Ethan Mendes, Justin Svegliato, Luke Bailey, Tiffany Wang, Isaac Ong, Karim Elmaaroufi, Pieter Abbeel, Trevor Darrell, Alan Ritter, Stuart Russell

[A Case Study of Instruction Tuning with Mixture of Parameter-Efficient Experts](https://openreview.net/forum?id=Rye1neGGUd)
<br>Oleksiy Ostapenko, Lucas Caccia, Zhan Su, Nicolas Le Roux, Laurent Charlin, Alessandro Sordoni

[Investigating the Catastrophic Forgetting in Multimodal Large Language Models](https://openreview.net/forum?id=RJyfNSoyDC)
<br>Yuexiang Zhai, Shengbang Tong, Xiao Li, Mu Cai, Qing Qu, Yong Jae Lee, Yi Ma

[LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms](https://openreview.net/forum?id=QxtL4Q1enz)
<br>Aditi Jha, Sam Havens, Jeremy Dohmann, Alexander Trott, Jacob Portes

[Let's Reinforce Step by Step](https://openreview.net/forum?id=QkdRqpClab)
<br>Sarah Pan, Vladislav Lialin, Sherin Muckatira, Anna Rumshisky

[DialogCC: An Automated Pipeline for Creating High-Quality Multi-modal Dialogue Datasets](https://openreview.net/forum?id=QUwcQFgA5a)
<br>Young-Jun Lee, Byungsoo Ko, Han-Gyu Kim, Jonghwan Hyeon, Ho-Jin Choi
<br>[[Poster]](/assets/pdf/96poster.pdf)

[Knowledge Augmented Instruction Tuning for Zero-shot Animal Species Recognition](https://openreview.net/forum?id=OQHckRYbpT)
<br>Zalan Fabian, Zhongqi Miao, Chunyuan Li, Yuanhan Zhang, Ziwei Liu, Andres Hernandez, Pablo Arbelaez, Andrés Link, Andrés Montes-Rojas, Rafael Escucha, Laura Siabatto, Rahul Dodhia, Juan Lavista Ferres

[Reward Model Ensembles Help Mitigate Overoptimization](https://openreview.net/forum?id=NiQYQEPUsA)
<br>Thomas Coste, Usman Anwar, Robert Kirk, David Krueger

[NexusRaven: a commercially-permissive Language Model for function calling](https://openreview.net/forum?id=Md6RUrGz67)
<br>Venkat Krishna Srinivasan, Zhen Dong, Banghua Zhu, Brian Yu, Hanzi Mao, Damon Mosk-Aoyama, Kurt Keutzer, Jiantao Jiao, Jian Zhang

[How Long Can Context Length of Open-Source LLMs truly Promise?](https://openreview.net/forum?id=LywifFNXV5)
<br>Dacheng Li, Rulin Shao, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph Gonzalez, Ion Stoica, Xuezhe Ma, Hao Zhang

[Learning to Generate Better Than Your LLM](https://openreview.net/forum?id=LqISMaceov)
<br>Jonathan Chang, Kianté Brantley, Rajkumar Ramamurthy, Dipendra Misra, Wen Sun

[From Classification to Generation: Insights into Crosslingual Retrieval Augmented ICL](https://openreview.net/forum?id=KLPLCXo4aD)
<br>Xiaoqian Li, Ercong Nie, Sheng Liang

[Reward Model Aggregation](https://openreview.net/forum?id=KGBNAJCuPf)
<br>Zihao Wang, Chirag Nagpal, Alexander D'Amour, Victor Veitch, Sanmi Koyejo

[Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions](https://openreview.net/forum?id=IqJ3CU3flr)
<br>Taehyeon Kim, Joonkee Kim, Gihun Lee, Se-Young Yun

[Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language](https://openreview.net/forum?id=IPJqprsrNX)
<br>Di Jin, Shikib Mehri, Devamanyu Hazarika, Aishwarya Padmakumar, SUNGJIN LEE, Yang Liu, Mahdi Namazifar

[Releasing the CRaQAn (Coreference Resolution in Question-Answering): An open-source dataset and dataset creation methodology using instruction-following models](https://openreview.net/forum?id=HgSViBZd1A)
<br>Rob Grzywinski, Joshua D'Arcy, Robert Naidoff, Ashish Shukla, Alex Browne, Ren Gibbons, Brinnae Bent

[CIEM: Contrastive Instruction Evaluation Method for Better Instruction Tuning](https://openreview.net/forum?id=HVduJbHSSO)
<br>Hongyu Hu, Jiyuan Zhang, Minyi Zhao, Zhenbang Sun

[Understanding Hidden Context in Preference Learning: Consequences for RLHF](https://openreview.net/forum?id=GO8aPQ9Odp)
<br>Anand Siththaranjan, Cassidy Laidlaw, Dylan Hadfield-Menell

[Past as a Guide: Leveraging Retrospective Learning for Python Code Completion](https://openreview.net/forum?id=G8ArB0aApM)
<br>Seungyoun Shin, Seunggyu Chang, Sungjoon Choi

[FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets](https://openreview.net/forum?id=FuOMomaQa8)
<br>Neng Wang, Hongyang Yang, Christina Wang

[Large Language Models are Zero Shot Hypothesis Proposers](https://openreview.net/forum?id=EAuteBjTMw)
<br>Biqing Qi, Kaiyan Zhang, Haoxiang Li, Kai Tian, Sihang Zeng, Zhang-Ren Chen, Bowen Zhou

[OctoPack: Instruction Tuning Code Large Language Models](https://openreview.net/forum?id=CjrPqvvUXL)
<br>Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam Singh, Xiangru Tang, Leandro Von Werra, Shayne Longpre

[Approximate Clustering for Extracting Task Relationships in Multi-Instruction Tuning](https://openreview.net/forum?id=CZJOOFgXZj)
<br>Dongyue Li, Jinhong Yu, Hongyang Zhang

[Understanding the Effects of RLHF on LLM Generalisation and Diversity](https://openreview.net/forum?id=Bc3S2G1PxH)
<br>Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, Edward Grefenstette, Roberta Raileanu

[Group Preference Optimization: Few-Shot Alignment of Large Language Models](https://openreview.net/forum?id=7KxUgWTZbz)
<br>Siyan Zhao, John Dang, Aditya Grover

[Platypus: Quick, Cheap, and Powerful Refinement of LLMs](https://openreview.net/forum?id=6579t0X8X2)
<br>Ariel Lee, Cole Hunter, Nataniel Ruiz

[FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets](https://openreview.net/forum?id=5dI6ZphLYX)
<br>Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang, Seungone Kim, Yongrae Jo, James Thorne, Juho Kim, Minjoon Seo

[Learning Interactive Real-World Simulators](https://openreview.net/forum?id=5O9JBt35zg)
<br>Sherry Yang, Yilun Du, Seyed Kamyar Seyed Ghasemipour, Jonathan Tompson, Dale Schuurmans, Pieter Abbeel

[FinGPT: Democratizing Internet-scale Data for Financial Large Language Models](https://openreview.net/forum?id=5BqWC1Fz8F)
<br>Xiao-Yang Liu, Guoxuan Wang, Hongyang Yang, Daochen Zha

[Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics](https://openreview.net/forum?id=4YlMoQoNhL)
<br>Haoqin Tu, Bingchen Zhao, Chen Wei, Cihang Xie

[A Monte Carlo Language Model Pipeline for Zero-Shot Sociopolitical Event Extraction](https://openreview.net/forum?id=3xGnOrUqt1)
<br>Erica Cai, Brendan O'Connor

[An Empirical Study of Scaling Instruct-Tuned Large Multimodal Models](https://openreview.net/forum?id=3846Xhv7mm)
<br>Yadong Lu, Chunyuan Li, Haotian Liu, Jianwei Yang, Jianfeng Gao, yelong shen

[For Distillation, Tokens Are Not All You Need](https://openreview.net/forum?id=2fc5GOPYip)
<br>Mrigank Raman, Pranav Mani, Davis Liang, Zachary Lipton

[Investigating the Effectiveness of Task-Agnostic Prefix Prompt for Instruction Following](https://openreview.net/forum?id=1TFhamIXNn)
<br>Seonghyeon Ye, Hyeonbin Hwang, Sohee Yang, Hyeongu Yun, Yireun Kim, Minjoon Seo

[Simulating Iterative Human-AI Interaction in Programming with LLMs](https://openreview.net/forum?id=0nRcZeeE5f)
<br>Hussein Mozannar, Valerie Chen, Dennis Wei, Prasanna Sattigeri, Manish Nagireddy, Subhro Das, Ameet Talwalkar, David Sontag

[Balancing Multiple Objectives for Efficient Metaprompts for Data Labeling Tasks with Extensive Guidelines](https://openreview.net/forum?id=0U1ZHdWX3l)
<br>Tobias Schnabel, Jennifer Neville

-->